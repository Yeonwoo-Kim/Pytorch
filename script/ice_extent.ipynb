{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "ice extent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "_Ic9-07DHxT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eUyKWXePHxUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2qJUf8nRHxUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seaice_data = pd.read_csv('/content/seaice_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HktLRXB8HxUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime as dt\n",
        "from dateutil.parser import parse\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vunb15iOHxUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toYearFraction(date):\n",
        "    def sinceEpoch(date): # returns seconds since epoch\n",
        "        return time.mktime(date.timetuple())\n",
        "    s = sinceEpoch\n",
        "\n",
        "    year = date.year\n",
        "    startOfThisYear = dt(year=year, month=1, day=1)\n",
        "    startOfNextYear = dt(year=year+1, month=1, day=1)\n",
        "    yearElapsed = s(date) - s(startOfThisYear)\n",
        "    yearDuration = s(startOfNextYear) - s(startOfThisYear)\n",
        "    # 초단위로 1년 / 현재날짜 의 비율 \n",
        "    fraction = yearElapsed/yearDuration\n",
        "    return date.year + fraction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ObJP_otXHxVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_decimal_year = []\n",
        "\n",
        "train_decimal_year.append(toYearFraction(parse(\"1978-11-15\")))\n",
        "train_decimal_year.append(toYearFraction(parse(\"1978-12-15\")))\n",
        "\n",
        "for i in range(1979, 2019):\n",
        "  if i == 2016:\n",
        "    continue\n",
        "  for m in range(1 , 13):\n",
        "    flag = int(m / 10)\n",
        "    if flag == 0:\n",
        "      date = (\"{}-0{}-15\".format(i,m))\n",
        "    else:\n",
        "      date = (\"{}-{}-15\".format(i,m))\n",
        "    train_decimal_year.append(toYearFraction(parse(date)))\n",
        "\n",
        "train_decimal_year.append(toYearFraction(parse(\"2019-01-15\")))\n",
        "train_decimal_year.append(toYearFraction(parse(\"2019-02-15\")))\n",
        "train_decimal_year.append(toYearFraction(parse(\"2019-03-15\")))\n",
        "train_decimal_year.append(toYearFraction(parse(\"2019-04-15\")))\n",
        "train_decimal_year.append(toYearFraction(parse(\"2019-05-15\")))\n",
        "\n",
        "train_decimal_year = np.array(train_decimal_year)\n",
        "train_decimal_year.shape\n",
        "seaice_data = seaice_data.drop(['month'],axis = 1)\n",
        "\n",
        "for i in range(475):\n",
        "  seaice_data.iloc[i,0] = train_decimal_year[i]\n",
        "\n",
        "seaice_data.tail(30)\n",
        "seaice_data.iloc[447:475]\n",
        "train_csv = seaice_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aRCAOXnnHxVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_carbon = np.array(seaice_data.iloc[0:447,0:4])\n",
        "x_seaice = np.array(seaice_data.iloc[0:447,5])\n",
        "y_carbon = np.array(seaice_data.iloc[0:447,4])\n",
        "scaler = RobustScaler()\n",
        "x_carbon_s = scaler.fit_transform(x_carbon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h3g-htwWHxVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "drop_prob = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPoMyaxiHxVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ctrain = torch.FloatTensor(x_carbon_s).to(device)\n",
        "y_ctrain = torch.FloatTensor(np.transpose(y_carbon[np.newaxis])).to(device)\n",
        "\n",
        "c_dataset = torch.utils.data.TensorDataset(x_ctrain, y_ctrain)\n",
        "c_data_loader = torch.utils.data.DataLoader(dataset = c_dataset,batch_size = batch_size, shuffle= True, drop_last = True)\n",
        "\n",
        "clinear1 = torch.nn.Linear(4,4,bias=True)\n",
        "clinear2 = torch.nn.Linear(4,1,bias=True)\n",
        "\n",
        "relu = torch.nn.ReLU()\n",
        "dropout = torch.nn.Dropout(p=drop_prob)\n",
        "\n",
        "torch.nn.init.xavier_normal_(clinear1.weight)\n",
        "torch.nn.init.xavier_normal_(clinear2.weight)\n",
        "torch.nn.init.xavier_normal_(clinear3.weight)\n",
        "torch.nn.init.xavier_normal_(clinear4.weight)\n",
        "\n",
        "cmodel = torch.nn.Sequential(clinear1,relu,clinear2).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i0_YeDMrHxVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "total_batch = len(c_data_loader)\n",
        "optimizer = optim.Adam(cmodel.parameters(), lr = 1)\n",
        "loss = torch.nn.MSELoss().to(device)\n",
        "\n",
        "nb_epochs = 500\n",
        "for epochs in range(nb_epochs + 1):\n",
        "  avg_cost = 0\n",
        "  for cX,cY in c_data_loader:\n",
        "    cX = cX.view(-1, 4).to(device)\n",
        "    cY = cY.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = cmodel(cX)\n",
        "    cost = loss(hypothesis,cY)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "  if epochs % 10 == 0:\n",
        "    print(\"epochs {}/{:4d}, cost {:.6f}\".format(epochs, nb_epochs, avg_cost))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o21KAH9_HxVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carbon_x_test = np.array(seaice_data.iloc[447:475,0:4])\n",
        "carbon_xs_test = scaler.fit_transform(carbon_x_test)\n",
        "x_ctest = torch.FloatTensor(carbon_xs_test).to(device)\n",
        "with torch.no_grad():\n",
        "  cmodel.eval()\n",
        "  carbon_pred = cmodel(x_ctest)\n",
        "carbon_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q3_Dobp5HxVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carbon_pred = carbon_pred.detach().cpu()\n",
        "carbon_pred = carbon_pred.detach().numpy()\n",
        "index = 0\n",
        "for i in range(447,475):\n",
        "   seaice_data.iloc[i,4] = carbon_pred[index]\n",
        "   index = index + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EhaxO6RVHxVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv = seaice_data\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(1)\n",
        "\n",
        "train_D = np.array(train_csv.iloc[:, 0:5])\n",
        "train_D = scaler.fit_transform(train_D)\n",
        "train_L = np.transpose(np.array(train_csv.iloc[:,5])[np.newaxis])\n",
        "train_D = torch.FloatTensor(train_D)\n",
        "train_L = torch.FloatTensor(train_L)\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(train_D, train_L)\n",
        "data_loader = torch.utils.data.DataLoader(dataset = dataset,batch_size = batch_size, shuffle= True, drop_last = True)\n",
        "\n",
        "linear1 = torch.nn.Linear(train_D.shape[1],32,bias=True)\n",
        "linear2 = torch.nn.Linear(32,128,bias=True)\n",
        "linear3 = torch.nn.Linear(128,64,bias=True)\n",
        "linear4 = torch.nn.Linear(64,64,bias=True) \n",
        "linear5 = torch.nn.Linear(64,1,bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "dropout = torch.nn.Dropout(p=drop_prob)\n",
        "\n",
        "model = torch.nn.Sequential(linear1,relu,\n",
        "                            linear2,relu,\n",
        "                            linear3,relu,\n",
        "                            linear4,relu,\n",
        "                            linear5).to(device)\n",
        "\n",
        "loss = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
        "\n",
        "torch.nn.init.kaiming_uniform_(linear1.weight)\n",
        "torch.nn.init.kaiming_uniform_(linear2.weight)\n",
        "torch.nn.init.kaiming_uniform_(linear3.weight)\n",
        "torch.nn.init.kaiming_uniform_(linear4.weight)\n",
        "torch.nn.init.kaiming_uniform_(linear5.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M1EFXqCRHxVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_batch = len(data_loader)\n",
        "for epoch in range(1000):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "\n",
        "        X = X.view(-1, train_D.shape[1]).to(device)      \n",
        "        Y = Y.to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()       \n",
        "        hypothesis = model(X)        \n",
        "        cost = loss(hypothesis, Y)\n",
        "        # Backparopagation\n",
        "        cost.backward()       \n",
        "        optimizer.step()       \n",
        "        avg_cost += cost / total_batch\n",
        "    if epoch % 10 == 0:\n",
        "      print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OrnCoGWeHxVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_csv = pd.read_csv('/content/seaice_test.csv')\n",
        "\n",
        "test_decimal_year = []\n",
        "\n",
        "for m in range(1 , 13):\n",
        "  flag = int(m / 10)\n",
        "  if flag == 0:\n",
        "    date = (\"2016-0{}-15\".format(m))\n",
        "  else:\n",
        "    date = (\"2016-{}-15\".format(m))\n",
        "  test_decimal_year.append(toYearFraction(parse(date)))\n",
        "\n",
        "test_decimal_year = np.array(test_decimal_year )\n",
        "test_decimal_year\n",
        "\n",
        "test_csv = test_csv.drop(['month'],axis = 1)\n",
        "\n",
        "for i in range(12):\n",
        "  test_csv.iloc[i,0] = test_decimal_year[i]\n",
        "\n",
        "test_D = scaler.transform(np.array(test_csv))\n",
        "test_D = torch.FloatTensor(test_D).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  pred = model(test_D).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3JgCK8SkHxVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv('./seaice_sample.csv')\n",
        "sample['seaice_extent'] = pred.cpu().detach().numpy()\n",
        "sample.to_csv('./defense4.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
